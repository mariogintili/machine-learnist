# About artificial intelligence

This course allows you to apply AI programs to real life situations. An AI program can be defined as an *Inteligent agent*, they:

- Have sensors
- Have a state
- Perceive an input from the environment, and act on it.

AI is the art of making a decision based on the passed data. This cycle is called **"Perception action cycle"**.

![](https://raw.githubusercontent.com/mariogintili/machine-learnist/master/assets/machine-learning-001.png)

They act on their environment, although not environments are all the same. In this particular context we can divide them by **fully** and **partially** observable:

- Fully observable environments: Are those who provide all the information to make the ultimate choice: like counting cards in blackjack.

- Partially observable environments: Are those who's acting agents need to look back at previous gathered data in a "game" or "cycle" in order to make the optimal decision: like guessing the area a football player will aim to on a penalty kick.

# About Machine Learning

Machine Learning is the area that studies machines that can act and make decisions autonomously, regardless wether they act like humans or not. As an example consider [Google's AlphaGo](https://deepmind.com/alpha-go.html) as a solid example of applied machine learning.
AI has a set of conundrums that need to be explored before diving into ML. They are:

- **Intelligent agents have limited resources:** A machine might have available in order to deliver results. Since this is the type of task that requires a lot of computing power, achieving near real-time results can be quite hard.

- **Computation is local, but problems have global constraints:** "How can we get AI agents to address global problems using only local computation?" I'm not really sure what the lecturer actually means here. I think later on he'll try to leverage cloud computing to achieve better performance.

- **Logic is deductive, but many problems are not:** Some problems require [abductive reasoning](https://www.butte.edu/departments/cas/tipsheets/thinking/reasoning.html), which can be described as beginning with an incomplete set of observations and making a decision on it.

- **The world is dynamic, but knowledge is limited:** A program is only as good as the data's been fed. What can a program do when facing a new problem?

- **Problem solving, reasoning and learning are hard. But explanations/justifications are even harder:** Personally the biggest conundrum, it would be an awesome thing to plot a model that could easily then show you how to make the best decision.

# Characteristics of AI problems

**Note** For this section I've decided to swap the phrase "The world" used by the lecturer with "data" given my background. Same with "knowledge" and "program"

- Data arrives incrementally: Tuning a model might take longer than the expected

- Problems will exhibit recurring patterns

- Problems have multiple levels of granularity

- Some problems are computationally intractable

- The knowledge gathered by a program is static, even though the nature of the data it receives is dynamic

- Data is open-ended but programmes are limited

Another way to look at AI is to define it as the property that a program has to manage uncertainty, i.e: What to do, when you really don't know what to actually do. There
are reasons behind this uncertainty: like the **limits its sensors have**, **adversaries** (other agents in the system that damper the act of making the right decision) , **[stochastic](https://www.google.co.uk/search?q=define+stochastic&oq=define+stochastic&aqs=chrome..69i57j0l5.3246j0j7&sourceid=chrome&ie=UTF-8) environments** in which nothing can really predict an outcome,
**laziness** (in which the program was too lazy to do it (?)) and the most important which is **ignorance**, like neglecting relevant factors that might be perfectly measurable.

# A real life example

Consider [Watson from Jeopardy](https://en.wikipedia.org/wiki/Watson_(computer)). This AI machine is doing a lot of things: trying to understand what we ask for it, looking it up on it's knowledge based and then returning the most relevant
match in the form of a question. The important notions here are:

- Reasoning: Acknowledge input.
- Learning: Parse/transform input into usable datasets.
- Memory: the end result

These 3 pilars are deeply interconnected as per the following diagram:

![](https://raw.githubusercontent.com/mariogintili/machine-learnist/master/assets/ai-flowchart.png)

**Learning -> Reasoning** an agent is able to reason from an input after it's learned an outcome from a similar/same input.
**Reasoning -> Learning** an agent is able to learn new things after it's reasoned from an input.
**Learning -> Memory** an agent store it's findings in its memory.
**Memory -> Learning** an agent can learn more things if it knows more.
**Memory-> Reasoning** Reasoning requires knowledge to which memory provides access to.
**Reasoning -> Memory** is unified as learning.

This entire process is called *deliberation*.

There's another way to understand knowledge-based AI. You can contrast the previous school of thought to the following:

![](https://raw.githubusercontent.com/mariogintili/machine-learnist/master/assets/act-think-human-machine.png)

- Machine Learning goes to the top left cuadrant
- The semantic web goes to the rop right cuadrant.
- Airplaine autopilot goes to the bottom left cuadrant.
- An Improvisational robot goes to the bottom right cuadrant.

#  Bayes's [rule](https://en.wikipedia.org/wiki/Bayes%27_rule) and [network](https://en.wikipedia.org/wiki/Bayesian_network)

**TODO** Ellaborate on this...

I know Spanish isn't your first language, but I found an amazing video giving you a small demostration of Baye's rule:

- https://www.youtube.com/watch?v=zQqxBirepKw

# About data scientists

*Data Science is an interdisciplinary field about processes and systems to extract knowledge or insights from data in various forms, either structured or unstructured,
which is a continuation of some of the data analysis fields such as statistics, data mining, and predictive analytics, similar to Knowledge Discovery in Databases.* [Source](https://en.wikipedia.org/wiki/Data_science)

Data scientists need to have substantive expertise, they know which questions to ask, have data-interpreting skills and can make clear sense of the data structures that can answer his/her questions.

# Defining Machine Learning

It's a very large field. But defining some taxonomy.

What's being learned? You can learn parameters[expand], structure[expand], hidden concepts[hidden] - https://www.udacity.com/course/viewer#!/c-nd009/l-7196318710/m-48713482
What from? Supervised, Unsupervised, reinforcement
What for? Predictions, diagnostics, summarizations
How? Passive, Active, online, offline
Outputs? Classification, regression
Details? Generative, Discriminative

# Supervised Learning



**TODO**

- **Induction and deduction**  define induction; define deduction ; inductive bias ; abduction
- **Supervised Learning** function approximation, getting the right formula!
- **Unsupervised learning** You don't have tuples of an input and an output. It's a bit trickier than that, like say just having a bunch of inputs and then having to derive a structure from it. Finding a way to describe inputs. in practice this is like looking at a bunch of people in a crowd and then trying to decide how to sort them in groups. You'll come up with categories like "tall people"
- **Reinforcement learning** Learning from a delayed reward, i.e: getting an output after making a set of inputs.
