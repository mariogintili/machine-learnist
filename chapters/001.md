# About artificial intelligence

This course allows you to apply AI programs to real life situations. An AI program can be defined as an *Inteligent agent*, they:

- Have sensors
- Have a state
- Perceive an input from the environment, and act on it.

AI is the art of making a decision based on the passed data. This cycle is called **"Perception action cycle"**.

![](https://raw.githubusercontent.com/mariogintili/machine-learnist/master/assets/machine-learning-001.png)

They act on their environment, although not environments are all the same. In this particular context we can divide them by **fully** and **partially** observable:

- Fully observable environments: Are those who provide all the information to make the ultimate choice: like counting cards in blackjack.

- Partially observable environments: Are those who's acting agents need to look back at previous gathered data in a "game" or "cycle" in order to make the optimal decision: like guessing the area a football player will aim to on a penalty kick.

# About Machine Learning

Machine Learning is the area that studies machines that can act and make decisions autonomously, regardless wether they act like humans or not. As an example consider [Google's AlphaGo](https://deepmind.com/alpha-go.html) as a solid example of applied machine learning.
AI has a set of conundrums that need to be explored before diving into ML. They are:

- **Intelligent agents have limited resources:** A machine might have available in order to deliver results. Since this is the type of task that requires a lot of computing power, achieving near real-time results can be quite hard.

- **Computation is local, but problems have global constraints:** "How can we get AI agents to address global problems using only local computation?" I'm not really sure what the lecturer actually means here. I think later on he'll try to leverage cloud computing to achieve better performance.

- **Logic is deductive, but many problems are not:** Some problems require [abductive reasoning](https://www.butte.edu/departments/cas/tipsheets/thinking/reasoning.html), which can be described as beginning with an incomplete set of observations and making a decision on it.

- **The world is dynamic, but knowledge is limited:** A program is only as good as the data's been fed. What can a program do when facing a new problem?

- **Problem solving, reasoning and learning are hard. But explanations/justifications are even harder:** Personally the biggest conundrum, it would be an awesome thing to plot a model that could easily then show you how to make the best decision.

# Characteristics of AI problems

**Note** For this section I've decided to swap the phrase "The world" used by the lecturer with "data" given my background. Same with "knowledge" and "program"

- Data arrives incrementally: Tuning a model might take longer than the expected

- Problems will exhibit recurring patterns

- Problems have multiple levels of granularity

- Some problems are computationally intractable

- The knowledge gathered by a program is static, even though the nature of the data it receives is dynamic

- Data is open-ended but programmes are limited

Another way to look at AI is to define it as the property that a program has to manage uncertainty, i.e: What to do, when you really don't know what to actually do. There
are reasons behind this uncertainty: like the **limits its sensors have**, **adversaries** (other agents in the system that damper the act of making the right decision) , **[stochastic](https://www.google.co.uk/search?q=define+stochastic&oq=define+stochastic&aqs=chrome..69i57j0l5.3246j0j7&sourceid=chrome&ie=UTF-8) environments** in which nothing can really predict an outcome,
**laziness** (in which the program was too lazy to do it (?)) and the most important which is **ignorance**, like neglecting relevant factors that might be perfectly measurable.

# A real life example

Consider [Watson from Jeopardy](https://en.wikipedia.org/wiki/Watson_(computer)). This AI machine is doing a lot of things: trying to understand what we ask for it, looking it up on it's knowledge based and then returning the most relevant
match in the form of a question. The important notions here are:

- Reasoning: Acknowledge input.
- Learning: Parse/transform input into usable datasets.
- Memory: the end result

These 3 pilars are deeply interconnected as per the following diagram:

![](https://raw.githubusercontent.com/mariogintili/machine-learnist/master/assets/ai-flowchart.png)

**Learning -> Reasoning** an agent is able to reason from an input after it's learned an outcome from a similar/same input.
**Reasoning -> Learning** an agent is able to learn new things after it's reasoned from an input.
**Learning -> Memory** an agent store it's findings in its memory.
**Memory -> Learning** an agent can learn more things if it knows more.
**Memory-> Reasoning** Reasoning requires knowledge to which memory provides access to.
**Reasoning -> Memory** is unified as learning.

This entire process is called *deliberation*.

There's another way to understand knowledge-based AI. You can contrast the previous school of thought to the following:

![](https://raw.githubusercontent.com/mariogintili/machine-learnist/master/assets/act-think-human-machine.png)

- Machine Learning goes to the top left cuadrant
- The semantic web goes to the rop right cuadrant.
- Airplaine autopilot goes to the bottom left cuadrant.
- An Improvisational robot goes to the bottom right cuadrant.

#  Bayes's [rule](https://en.wikipedia.org/wiki/Bayes%27_rule) and [network](https://en.wikipedia.org/wiki/Bayesian_network)

**In theory** Bayes's rule provides the odds of an Event **A** to the odds of an event **A1** before and after conditioning another event **B**. The odds of **A** to **A1** are just merely the ratio of probabilities of the 2 events. [source](https://en.wikipedia.org/wiki/Bayes%27_rule)

I found the previous explanation excessively complicated, other resources I tried to lookup in online, seemed rather complex as well. I'm fully aware that not everyone reading this is a Spanish speaker, but [Unicoos](https://www.youtube.com/watch?v=zQqxBirepKw) was by far the best resource I could find online.

Just for **this** specific occasion I will traduce and illustrate the example employed by Unicoos to expand on this topic.

**In practice** We'll consider the following problem to illustrate some of Baye's swag:

There's 2 bags filled with both white and black balls, **Bag A** has 3 black balls and 4 white balls and **Bag B** has 5 black balls and 3 white balls.

Without looking, a ball is pulled out from **Bag A** and added to **Bag B**.

There's a lot of things that can be extracted from the previous sentence, even though the exercise hasn't expose questions to be answered! To further ellaborate:

**Initial state**

![](https://raw.githubusercontent.com/mariogintili/machine-learnist/master/assets/bayes-theorem-1.JPG)

In this example let `P(x)` be the probability of something to happen. `N1` is the probability of the **Bag B** to have a new black ball after the action is performed and `B1` to be the same for a white ball.

So it's `3/7` likely that the new ball on B will be black and `4/7` for the new ball to be white.

The enunciate from the exercise continues, stating: After one ball has been extracted from bag A. Again another ball is extracted from B without looking. What's the likelihood for each colour to be drawn here?

![](https://raw.githubusercontent.com/mariogintili/machine-learnist/master/assets/bayes-theorem-2.JPG)

There's 4 possible scenarios here, expressed as:

- `P(b2/n1)` it's `3/9` likely that the second ball will be white given that the first one was black
- `P(n2/n1)` it's `6/9` likely that the second ball will be black given that the first one was black.
- `P(b2/b1)` it's `4/9` likely that the first one will be white given that the first one was white.
- `P(n2/b1)` it's `5/9` likely that the second ball will be black given that the first one was white.

As you can see we've expanded on the theorem mentioned before.

The probability - for the second ball to be black - can be expressed as:

`P(N2) = (3/7 * 6/9) + (4/7 * 5/9)`

# About data scientists

*Data Science is an interdisciplinary field about processes and systems to extract knowledge or insights from data in various forms, either structured or unstructured,
which is a continuation of some of the data analysis fields such as statistics, data mining, and predictive analytics, similar to Knowledge Discovery in Databases.* [Source](https://en.wikipedia.org/wiki/Data_science)

Data scientists need to have substantive expertise, they know which questions to ask, have data-interpreting skills and can make clear sense of the data structures that can answer his/her questions.

# Defining Machine Learning

It's a very large field. But defining some taxonomy.

What's being learned? You can learn parameters[expand], structure[expand], hidden concepts[hidden] - https://www.udacity.com/course/viewer#!/c-nd009/l-7196318710/m-48713482
What from? Supervised, Unsupervised, reinforcement
What for? Predictions, diagnostics, summarizations
How? Passive, Active, online, offline
Outputs? Classification, regression
Details? Generative, Discriminative

**TODO**

- **Induction and deduction**  define induction; define deduction ; inductive bias ; abduction
- **Supervised Learning** function approximation, getting the right formula!
- **Unsupervised learning** You don't have tuples of an input and an output. It's a bit trickier than that, like say just having a bunch of inputs and then having to derive a structure from it. Finding a way to describe inputs. in practice this is like looking at a bunch of people in a crowd and then trying to decide how to sort them in groups. You'll come up with categories like "tall people"
- **Reinforcement learning** Learning from a delayed reward, i.e: getting an output after making a set of inputs.

# Supervised Learning

For each training example theres'a "feature vector": x1, x2, xn...
And a "target label" Y

Consider a credit rating company, where the X's may correspond to multiple inputs like: Has the person defaulted before? How much does he/she earn? How many accounts does he/she have? etc..
And our target label Y would be the determination of wether this person will default or not.

SL is carried out on the given data and real occurrences caused on it. So it can the build a function that might approximate an accurate result.

<!-- function approximation image here -->

The goal in SL is to find F with some degree of error, so in the future you can find Y for any given X's.

## About Occam's Razor

This one of my favourite personal and I try my best to oblige by it. It basically consists of: given a set of hypothesis you should
choose the ones that makes the least amount of assumptions. For example say you lost your car keys this morning, you could say that:

- A) They were taken by aliens
- B) You left them in a pair of trousers you wore yesterday

and you decide to go for option B)

**TODO** Expand on aiming for low complexity for better performance, the concept of "overfitting", "generalization error", "overfitting error" and "training data error"

# Classification vs Regression

in Classification the target labels are discreet, static.
in Regression the target is not static, targets are expressed in the form of relationships. Again, trying to find F(x).

## Linear regression

We have a vector of inputs, like `[x1, x2, x3 ...xn]`

Where we try to find `y = f(x)`. In linear regresion, the function has a particular form

```
f(x) = m * x + b
```

I know sebastian asked not to use maths, but I went ahead and did anyways :godmode: [How to solve the last quiz](http://www.sosmath.com/soe/SE211105/SE211105.html)

To define Linear regression you need to understand what you want to minimise, which is the residual error after you've fitted the linear function as good as possible.

See [LOSS function](https://en.wikipedia.org/wiki/Loss_function)

remember to give feedback here https://discussions.udacity.com/t/about-the-mlnd-introduction-to-machine-learning-category/159909/8
