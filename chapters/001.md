# About artificial intelligence

This course allows you to apply AI programs to real life situations. An AI program can be defined as an *Inteligent agent*, they:

- Have sensors
- Have a state
- Perceive an input from the environment, and act on it.

AI is the art of making a decision based on the passed data. This cycle is called **"Perception action cycle"**.

![](https://raw.githubusercontent.com/mariogintili/machine-learnist/master/assets/machine-learning-001.png)

They act on their environment, although not environments are all the same. In this particular context we can divide them by **fully** and **partially** observable:

- Fully observable environments: Are those who provide all the information to make the ultimate choice: like counting cards in blackjack.

- Partially observable environments: Are those who's acting agents need to look back at previous gathered data in a "game" or "cycle" in order to make the optimal decision: like guessing the area a football player will aim to on a penalty kick.

# About Machine Learning

Machine Learning is the area that studies machines that can act and make decisions autonomously, regardless wether they act like humans or not. As an example consider [Google's AlphaGo](https://deepmind.com/alpha-go.html) as a solid example of applied machine learning.
AI has a set of conundrums that need to be explored before diving into ML. They are:

- **Intelligent agents have limited resources:** A machine might have available in order to deliver results. Since this is the type of task that requires a lot of computing power, achieving near real-time results can be quite hard.

- **Computation is local, but problems have global constraints:** "How can we get AI agents to address global problems using only local computation?" I'm not really sure what the lecturer actually means here. I think later on he'll try to leverage cloud computing to achieve better performance.

- **Logic is deductive, but many problems are not:** Some problems require [abductive reasoning](https://www.butte.edu/departments/cas/tipsheets/thinking/reasoning.html), which can be described as beginning with an incomplete set of observations and making a decision on it.

- **The world is dynamic, but knowledge is limited:** A program is only as good as the data's been fed. What can a program do when facing a new problem?

- **Problem solving, reasoning and learning are hard. But explanations/justifications are even harder:** Personally the biggest conundrum, it would be an awesome thing to plot a model that could easily then show you how to make the best decision.

# Characteristics of AI problems

**Note** For this section I've decided to swap the phrase "The world" used by the lecturer with "data" given my background. Same with "knowledge" and "program"

- Data arrives incrementally: Tuning a model might take longer than the expected

- Problems will exhibit recurring patterns

- Problems have multiple levels of granularity

- Some problems are computationally intractable

- The knowledge gathered by a program is static, even though the nature of the data it receives is dynamic

- Data is open-ended but programmes are limited

Another way to look at AI is to define it as the property that a program has to manage uncertainty, i.e: What to do, when you really don't know what to actually do. There
are reasons behind this uncertainty: like the **limits its sensors have**, **adversaries** (other agents in the system that damper the act of making the right decision) , **[stochastic](https://www.google.co.uk/search?q=define+stochastic&oq=define+stochastic&aqs=chrome..69i57j0l5.3246j0j7&sourceid=chrome&ie=UTF-8) environments** in which nothing can really predict an outcome,
**laziness** (in which the program was too lazy to do it (?)) and the most important which is **ignorance**, like neglecting relevant factors that might be perfectly measurable.

# A real life example

Consider [Watson from Jeopardy](https://en.wikipedia.org/wiki/Watson_(computer)). This AI machine is doing a lot of things: trying to understand what we ask for it, looking it up on it's knowledge based and then returning the most relevant
match in the form of a question. The important notions here are:

- Reasoning: Acknowledge input.
- Learning: Parse/transform input into usable datasets.
- Memory: the end result

These 3 pilars are deeply interconnected as per the following diagram:



[cont]


### Observations

- Terms "Machine Learning" and "AI problems" seem to be used as exchangeably by different lecturers even though they are not.
- High level of fragmentation between lecture. All lesons are 5 mins or less.
- List-like format for everything: IMO pill-sized knowledge is good for revisiting a topic but not when its first approached, a full dissertation should be used instead.
- Found the words from lecturers in the pre-assessment depressing.
